<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>human fatigue system</title>
    <link rel="stylesheet" href="drive.css">
     <link rel="stylesheet" href="https://pyscript.net/latest/pyscript.css" />
    <script defer src="https://pyscript.net/latest/pyscript.js"></script>

</head>
<body>
    <div class="head">
        <nav class="headbox">
            <div class="img"><img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSfdO3JM5LnmC-oSCmBSqdqv0SNyXmadmi7AA&usqp=CAU" alt=""></div>
            <div class="proname"><p>Human Fatigue System</p></div>
            <div class="about"><a href="">About us</a></div>
        </nav>
    </div>
    <div class="main">
        <div class="con"><h1>What is Human fatigue System</h1>
        <p>Human Fatigue Detection Systems are a cutting-edge technology that have the potential to greatly increase safety and performance in a variety of industries.</p></div>
        <div class="con2"><div class="about"><h1>About the Human fatigue system</h1>
        <p class="text">A human fatigue detection system is a project that aims to develop a technology that can detect and monitor the level of fatigue in humans.This system can use various methods such as analyzing physiological signals, tracking eye movements, or monitoring changes in behavior to determine the level of fatigue in a person. The goal of this project is to improve safety in various industries, such as transportation or healthcare, by alerting individuals or supervisors when a person is too fatigued to perform their duties effectively and safely. The system can also be used to collect data on fatigue patterns and help develop strategies to prevent fatigue-related incidents in the future.</p>
    </div>
    <div class="photo"><img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQvC7wtCMC2SEaeiGJWylUZuxpltMBwnYspIQ&usqp=CAU" alt=""></div>

</div>
<div class="system">
    <div class="heading"><h1>start the system</h1>
    <h2>Tips to use system </h2>
<div class="im"><li class="1">Adjust your device in front of your face.</li>
    <li class="im2">Ensure that you should have a good internet connectivity.</li>
    <li class="im3">click on below button to start the system.</li>
    <li class="im4">after click on the button,allow your camera.</li></div></div>
</div>
<div class="buttn"><button class="btn">Start now</button></div>
<py-script>#Importing OpenCV Library for basic image processing functions
    import cv2
    # Numpy for array related functions
    import numpy as np
    # Dlib for deep learning based Modules and face landmark detection
    import dlib
    #face_utils for basic operations of conversion
    from imutils import face_utils
    
    
    #Initializing the camera and taking the instance
    cap = cv2.VideoCapture(0)
    
    #Initializing the face detector and landmark detector
    detector = dlib.get_frontal_face_detector()
    predictor = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")
    
    #status marking for current state
    sleep = 0
    drowsy = 0
    active = 0
    status=""
    color=(0,0,0)
    
    def compute(ptA,ptB):
        dist = np.linalg.norm(ptA - ptB)
        return dist
    
    def blinked(a,b,c,d,e,f):
        up = compute(b,d) + compute(c,e)
        down = compute(a,f)
        ratio = up/(2.0*down)
    
        #Checking if it is blinked
        if(ratio>0.25):
            return 2
        elif(ratio>0.21 and ratio <=0.25):
            return 1
        else:
            return 0
    
    
    while True:
        _, frame = cap.read()
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    
        faces = detector(gray)
        #detected face in faces array
        for face in faces:
            x1 = face.left()
            y1 = face.top()
            x2 = face.right()
            y2 = face.bottom()
    
            face_frame = frame.copy()
            cv2.rectangle(face_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
    
            landmarks = predictor(gray, face)
            landmarks = face_utils.shape_to_np(landmarks)
    
            #The numbers are actually the landmarks which will show eye
            left_blink = blinked(landmarks[36],landmarks[37], 
                landmarks[38], landmarks[41], landmarks[40], landmarks[39])
            right_blink = blinked(landmarks[42],landmarks[43], 
                landmarks[44], landmarks[47], landmarks[46], landmarks[45])
            
            #Now judge what to do for the eye blinks
            if(left_blink==0 or right_blink==0):
                sleep+=1
                drowsy=0
                active=0
                if(sleep>6):
                    status="SLEEPING !!!"
                    color = (255,0,0)
    
            elif(left_blink==1 or right_blink==1):
                sleep=0
                active=0
                drowsy+=1
                if(drowsy>6):
                    status="Drowsy !"
                    color = (0,0,255)
    
            else:
                drowsy=0
                sleep=0
                active+=1
                if(active>6):
                    status="Active :"
                    color = (0,255,0)
                
            cv2.putText(frame, status, (100,100), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color,3)
    
            for n in range(0, 68):
                (x,y) = landmarks[n]
                cv2.circle(face_frame, (x, y), 1, (255, 255, 255), -1)
    
        cv2.imshow("Frame", frame)
        cv2.imshow("Result of detector", face_frame)
        key = cv2.waitKey(1)
        if key == 27:
              break</py-script>
</div>
</body>
</html>
